The results discussed below can be found in the sortinfo.txt file. 
5 sorting algorithms and a Binary Tree were each tested on data of sizes 50, 5000, and 100000.

----------

In the rubric, we were told that the Big-O of Shell sort was O(n ^1.25).
No other sources corroborated this, but rather, other sources said it was the average of Shell sort.
The time didn't begin to agree with our calculations until we committed that Big-O of Shell Sort was O(n(log(n))^2).
Overall, this algorithm was difficult, since there doesn't seem to be a standard, conventional Big-O here.

The operations for Binary Tree did not seem to match up well either.
Exactly how the number of iterations was to be counted was not made perfectly clear, and based on the results given
back from the routine, not helpful in seeing how the Big-O of a Binary Tree is supposedly O(log(n)).

Besides the initial trouble with Shellsort and the Binary Tree, all results were valid. 
Quick sort seemed unanimously to be the fastest of all of them, regardless of size. 
One interesting question was whether or not data size made a difference.
In some cases, we found that the number of iterations of n was not always 0 on already-sorted data. 
We noticed that Shellsort began to overshoot its Big-O value with the array of 100000. 
So indeed, data size does make a difference in some cases.
